{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('equity_value_data.csv')\n",
    "#data.drop('Unnamed: 0',axis = 1, inplace =True)\n",
    "data['date'] = [dt.datetime.strptime(i[0:10], \"%Y-%m-%d\") for i in data.timestamp]\n",
    "#data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timestring = [i[11:19] for i in data.timestamp]\n",
    "# x = pd.DataFrame(timestring)\n",
    "# x.rename(columns = {0:'time'},inplace = True)\n",
    "# x.time.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.min(data.close_equity)\n",
    "## 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer A: The percentage of users that have churned is\n",
      "0.04996418338108882\n"
     ]
    }
   ],
   "source": [
    "############# ANSWER TO QUESTION A ###############\n",
    "data['interval'] = pd.DataFrame(data.groupby('user_id')['date'].diff())\n",
    "data['interval_days'] = [i.total_seconds()/(24 * 60 * 60) for i in data['interval']]\n",
    "churndata = data[data.interval_days >= 28] \n",
    "churnid = list(churndata.user_id.unique())\n",
    "churnrate = len(churnid)/len(list(data.user_id.unique()))\n",
    "print('Answer A: The percentage of users that have churned is')\n",
    "print(churnrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('features_data.csv')\n",
    "features['churned'] = features.user_id.apply(lambda x: 1 if x in churnid else 0)\n",
    "# print(features.head())\n",
    "# print(features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "risk_tolerance has the following values:\n",
      "['high_risk_tolerance' 'med_risk_tolerance' 'low_risk_tolerance']\n",
      "\n",
      "investment_experience has the following values:\n",
      "['limited_investment_exp' 'no_investment_exp' 'good_investment_exp'\n",
      " 'extensive_investment_exp']\n",
      "\n",
      "liquidity_needs has the following values:\n",
      "['very_important_liq_need' 'not_important_liq_need'\n",
      " 'somewhat_important_liq_need']\n",
      "\n",
      "platform has the following values:\n",
      "['Android' 'iOS' 'both']\n",
      "\n",
      "instrument_type_first_traded has the following values:\n",
      "['stock' 'etp' 'adr' 'wrt' 'mlp' '0' 'lp' 'rlt' 'reit' 'cef' 'tracking']\n",
      "\n",
      "time_horizon has the following values:\n",
      "['med_time_horizon' 'short_time_horizon' 'long_time_horizon']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in ['risk_tolerance', 'investment_experience', 'liquidity_needs',\n",
    "       'platform', 'instrument_type_first_traded','time_horizon']:\n",
    "    print(i + ' has the following values:')\n",
    "    print(features[i].unique())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfinst = pd.DataFrame(df.groupby('instrument_type_first_traded')['user_id'].count())\n",
    "# dfinstchurned = pd.DataFrame(df[df.churned == 1].groupby('instrument_type_first_traded')['user_id'].count())\n",
    "# print(dfinst.sort_values('user_id',ascending = False))\n",
    "# print(dfinstchurned.sort_values('user_id', ascending = False))\n",
    "# (dfinstchurned/dfinst).sort_values('user_id', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = features.copy()\n",
    "#********* encode category features\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "ohe = OneHotEncoder(sparse = False)\n",
    "ohedf = pd.DataFrame(ohe.fit_transform(df[['platform','instrument_type_first_traded']]))\n",
    "ohedf.rename(columns = {0:'Android', 1:'both', 2:'iOS',\n",
    "                       3:'0',4:'adr',5:'cef',6:'etp',7:'lp',8:'mlp',9:'reit',10:'rlt',11:'stock',12:'tracking',13:'wrt'}, inplace = True)\n",
    "\n",
    "oe = OrdinalEncoder(categories = [['low_risk_tolerance', 'med_risk_tolerance', 'high_risk_tolerance'],\n",
    "                                  ['no_investment_exp','limited_investment_exp','good_investment_exp','extensive_investment_exp'],\n",
    "                                  ['not_important_liq_need','somewhat_important_liq_need','very_important_liq_need'],\n",
    "                                  ['short_time_horizon','med_time_horizon','long_time_horizon']\n",
    "                                 ])\n",
    "oedf = pd.DataFrame(oe.fit_transform(df[['risk_tolerance','investment_experience','liquidity_needs','time_horizon']]))\n",
    "oedf.rename(columns = dict(zip([0,1,2,3],['risk_tolerance','investment_experience','liquidity_needs','time_horizon'])), inplace = True)  \n",
    "\n",
    "dffinal = pd.merge(ohedf, oedf, how = 'outer',left_index = True, right_index = True)\n",
    "dffinal = pd.merge(df[['time_spent','first_deposit_amount','user_id','churned']],dffinal, how = 'outer', left_index = True, right_index = True)\n",
    "dffinal.set_index('user_id',inplace = True)\n",
    "#dffinal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#********* scaling features with max > 1\n",
    "to_scale = [col for col in dffinal.columns if dffinal[col].max()>1]\n",
    "mms = MinMaxScaler()\n",
    "scaled = pd.DataFrame(mms.fit_transform(dffinal[to_scale]),columns = to_scale)\n",
    "scaled.set_index(dffinal.index, inplace = True)\n",
    "\n",
    "dffinal.drop(to_scale, axis = 1, inplace = True)\n",
    "dffinal = pd.concat([scaled,dffinal],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#******** display all fields from the final data set\n",
    "fields_all = [\n",
    "              'time_spent', 'first_deposit_amount', \n",
    "              'risk_tolerance','investment_experience', 'liquidity_needs', 'time_horizon', \n",
    "              'churned',\n",
    "              'Android', 'both', 'iOS', \n",
    "              '0', 'adr', 'cef', 'etp', 'lp', 'mlp', 'reit', 'rlt', 'stock', 'tracking', 'wrt'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#******** remove one dummy from each non-ordinal category to avoid multicollinearity\n",
    "# remove 'Android' based on correlation\n",
    "# remove  'Stock'  based on VIF\n",
    "# remove 'churned' the dependent variable\n",
    "features_selected = [\n",
    "                    'time_spent', 'first_deposit_amount', \n",
    "                    'risk_tolerance','investment_experience', 'liquidity_needs', 'time_horizon', \n",
    "                    'both', 'iOS',\n",
    "                    '0','adr', 'cef', 'etp', 'lp', 'mlp', 'reit', 'rlt','tracking', 'wrt' \n",
    "                     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature set and DV\n",
    "X = dffinal[features_selected]\n",
    "y = dffinal['churned']\n",
    "\n",
    "# Use VIF to check multicollinearity\n",
    "vif = pd.DataFrame([variance_inflation_factor(X.values, i) for i in range(X.shape[1])], index=X.columns)\n",
    "#print(vif)\n",
    "# vif of stock is still pretty large, hence removed\n",
    "#X.drop('stock', axis = 1, inplace = True)\n",
    "#vif = pd.DataFrame([variance_inflation_factor(X.values, i) for i in range(X.shape[1])], index=X.columns)\n",
    "#print(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set()\n"
     ]
    }
   ],
   "source": [
    "correlated_features = set()\n",
    "correlation_matrix = X.corr()\n",
    "for i in range(len(correlation_matrix.columns)):\n",
    "    for j in range(i):\n",
    "        if abs(correlation_matrix.iloc[i, j]) > 0.7:\n",
    "            colname = correlation_matrix.columns[i]\n",
    "            correlated_features.add(colname)\n",
    "print(correlated_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove correlated features\n",
    "#X.drop('iOS', axis = 1, inplace = True)\n",
    "\n",
    "# Use SMOTE to deal with imbalanced data\n",
    "sm = SMOTE(random_state = 50)\n",
    "X_sm, y_sm = sm.fit_resample(X,y)\n",
    "\n",
    "# Train-Test splitting\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_sm, y_sm, random_state = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X.shape)\n",
    "# print(X_sm.shape)\n",
    "# print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RFECV(estimator=RandomForestClassifier(random_state=100), scoring='f1')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use RFECV to select features\n",
    "\n",
    "#**** define a classifer\n",
    "#clf = LogisticRegression()\n",
    "#clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf = RandomForestClassifier(random_state = 100)\n",
    "\n",
    "# define RFECV\n",
    "rfecv  = RFECV(estimator = clf, step = 1, scoring = 'f1')\n",
    "\n",
    "# fit a model\n",
    "rfecv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 13\n"
     ]
    }
   ],
   "source": [
    "print('Optimal number of features: {}'.format(rfecv.n_features_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 7))\n",
    "# plt.title('Recursive Feature Elimination with CV', fontsize=13, fontweight='bold')\n",
    "# plt.xlabel('Number of features used', fontsize=13)\n",
    "# plt.ylabel('classification score', fontsize=13)\n",
    "# plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_, color='#303F9F', linewidth=2)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rfecv.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop features that were not selected\n",
    "X.drop(X.columns[np.where(rfecv.support_ == False)[0]], axis=1, inplace=True)\n",
    "X_sm.drop(X_sm.columns[np.where(rfecv.support_ == False)[0]], axis=1, inplace=True)\n",
    "X_train.drop(X_train.columns[np.where(rfecv.support_ == False)[0]], axis=1, inplace=True)\n",
    "X_test.drop(X_test.columns[np.where(rfecv.support_ == False)[0]], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>first_deposit_amount</td>\n",
       "      <td>0.340412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>time_spent</td>\n",
       "      <td>0.283236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>investment_experience</td>\n",
       "      <td>0.120819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>risk_tolerance</td>\n",
       "      <td>0.064993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>time_horizon</td>\n",
       "      <td>0.056948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>liquidity_needs</td>\n",
       "      <td>0.048801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>iOS</td>\n",
       "      <td>0.027806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>etp</td>\n",
       "      <td>0.015572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>both</td>\n",
       "      <td>0.014681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>adr</td>\n",
       "      <td>0.012557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mlp</td>\n",
       "      <td>0.006436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>wrt</td>\n",
       "      <td>0.003899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>reit</td>\n",
       "      <td>0.003840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       importance\n",
       "first_deposit_amount     0.340412\n",
       "time_spent               0.283236\n",
       "investment_experience    0.120819\n",
       "risk_tolerance           0.064993\n",
       "time_horizon             0.056948\n",
       "liquidity_needs          0.048801\n",
       "iOS                      0.027806\n",
       "etp                      0.015572\n",
       "both                     0.014681\n",
       "adr                      0.012557\n",
       "mlp                      0.006436\n",
       "wrt                      0.003899\n",
       "reit                     0.003840"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################### Answer to QUESTION C ##################\n",
    "featureimportance = pd.DataFrame(pd.Series(dict(zip(X.columns,rfecv.estimator_.feature_importances_))))\n",
    "featureimportance.rename(columns = {0:'importance'}).sort_values('importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93      1326\n",
      "           1       0.93      0.93      0.93      1327\n",
      "\n",
      "    accuracy                           0.93      2653\n",
      "   macro avg       0.93      0.93      0.93      2653\n",
      "weighted avg       0.93      0.93      0.93      2653\n",
      "\n",
      "[[1235   91]\n",
      " [  96 1231]]\n",
      "0.9222054118746339\n",
      "0.9145308302518883\n"
     ]
    }
   ],
   "source": [
    "#**** Re-fit the model\n",
    "clf.fit(X_train, y_train)\n",
    "y_predicted = clf.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_predicted))\n",
    "print(confusion_matrix(y_test, y_predicted))\n",
    "\n",
    "#*** perform cross validation\n",
    "print(cross_val_score(clf, X_train, y_train, cv = 5, scoring = 'precision').mean())\n",
    "print(cross_val_score(clf, X_train, y_train, cv = 5, scoring = 'recall').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      5305\n",
      "           1       0.72      0.82      0.76       279\n",
      "\n",
      "    accuracy                           0.97      5584\n",
      "   macro avg       0.85      0.90      0.88      5584\n",
      "weighted avg       0.98      0.97      0.98      5584\n",
      "\n",
      "[[5214   91]\n",
      " [  50  229]]\n"
     ]
    }
   ],
   "source": [
    "#**** Apply the model to the original dataset (without re-sampling from SMOTE)\n",
    "y_OriginalSample = clf.predict(X)\n",
    "print(classification_report(y, y_OriginalSample))\n",
    "print(confusion_matrix(y, y_OriginalSample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>895044c23edc821881e87da749c01034</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>458b1d95441ced242949deefe8e4b638</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>c7936f653d293479e034865db9bb932f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>b255d4bd6c9ba194d3a350b3e76c6393</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4a168225e89375b8de605cbc0977ae91</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>03880c726d8a4e5db006afe4119ad974</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ae8315109657f44852b24c6bca4decd6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>f29c174989f9737058fe808fcf264135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24843497d1de88b2e7233f694436cb3a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49ee0531ee9dfbce0e7d9afa1c3d86f4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5584 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  0\n",
       "user_id                            \n",
       "895044c23edc821881e87da749c01034  1\n",
       "458b1d95441ced242949deefe8e4b638  0\n",
       "c7936f653d293479e034865db9bb932f  0\n",
       "b255d4bd6c9ba194d3a350b3e76c6393  0\n",
       "4a168225e89375b8de605cbc0977ae91  0\n",
       "...                              ..\n",
       "03880c726d8a4e5db006afe4119ad974  1\n",
       "ae8315109657f44852b24c6bca4decd6  1\n",
       "f29c174989f9737058fe808fcf264135  0\n",
       "24843497d1de88b2e7233f694436cb3a  0\n",
       "49ee0531ee9dfbce0e7d9afa1c3d86f4  0\n",
       "\n",
       "[5584 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################### Answer to QUESTION B ##################\n",
    "pd.DataFrame(y_OriginalSample).set_index(dffinal.index).to_csv('classification_result.csv')\n",
    "pd.DataFrame(y_OriginalSample).set_index(dffinal.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
